{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNBhdEGHTnKrTAtHkYbWFWg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luis-arrieta/Building-Generative-AI-Powered-Applications-with-Python/blob/main/Voice_Assistant_with_OpenAI's_GPT_3_and_IBM_Watson.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Learning objectives ###\n",
        "\n",
        "At the end of this project, you will be able to:\n",
        "\n",
        "* Explain the basics of voice assistants and their various applications\n",
        "* Set up a development environment for building an assistant using Python, Flask, HTML, CSS, and Javascript\n",
        "* Implement speech-to-text functionality to allow the assistant to understand voice input from users\n",
        "* Integrate the assistant with OpenAI's GPT-3 model to give it a high level of intelligence and the ability to understand and respond to user requests\n",
        "* Implement text-to-speech functionality to allow the assistant to communicate with users through voice output\n",
        "* Combine all the above components to create a functional assistant that can take voice input and provide a spoken response\n",
        "* (Optional) Deploy the assistant to a web server for use by a wider audience"
      ],
      "metadata": {
        "id": "VBSlAp06PjZJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Understanding the interface ###\n",
        "In this project, the goal is to create an interface that allows communication with a voice assistant, and a backend to manage the sending and receiving of responses.\n",
        "\n",
        "The frontend will use HTML, CSS and Javascript with popular libraries such as Bootstrap for basic styling, Font Awesome for icons and JQuery for efficient handling of actions. The user interface will be similar to other voice assistant applications, like Google Assistant. The code for the interface is provided and the focus of the course is on building the voice assistant and integrating it with various services and APIs. The provided code will help you to understand how the frontend and backend interact, and as you go through it, you will learn about the important parts and how it works, giving you a good understanding of how the frontend works and how to create this simple web page.\n",
        "\n",
        "Run the following commands to receive the outline of the project, rename it to save it with another name and finally move into that directory."
      ],
      "metadata": {
        "id": "qUimbQEZRfcM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75RPBDGnPMMm"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/arora-r/chatapp-with-voice-and-openai-outline.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv chatapp-with-voice-and-openai-outline chatapp-with-voice-and-openai"
      ],
      "metadata": {
        "id": "kffPZ3lMQWtZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cd chatapp-with-voice-and-openai"
      ],
      "metadata": {
        "id": "zE7KJ8vaQa2S"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Understanding the server ###\n",
        "\n",
        "The server is how the application will run and communicate with all your services. Flask is a web development framework for Python and can be used as a backend for the application. It is a lightweight and simple framework that makes it quick and easy to build web applications.\n",
        "\n",
        "With Flask, you can create web pages and applications without needing to know a lot of complex coding or use additional tools or libraries. You can create your own routes and handle user requests, and it also allows you to connect to external APIs and services to retrieve or send data.\n",
        "\n",
        "This guided project uses Flask to handle the backend of your voice assistant. This means that you will be using Flask to create routes and handle HTTP requests and responses. When a user interacts with the voice assistant through the frontend interface, the request will be sent to the Flask backend. Flask will then process the request and send it to the appropriate service."
      ],
      "metadata": {
        "id": "m-7iSKNeSadS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "At the top of the file, there are several import statements. These statements are used to bring in external libraries and modules, which will be used in the current file. For instance, speech_to_text is a function inside the worker.py file, while openai is a package that needs to be installed to use the OpenAI's GPT-3 model. These imported packages, modules and libraries will allow you to access the additional functionalities and methods that they offer, making it easy to interact with the speech-to-text and GPT-3 model in your code.\n",
        "\n",
        "Underneath the imports, the Flask application is initialized, and a CORS policy is set. A CORS policy is used to allow or prevent web pages from making requests to different domains than the one that served the web page. Currently, it is set to * to allow any request.\n",
        "\n",
        "The server.py file consists of 3 functions which are defined as routes, and the code to start the server.\n",
        "\n",
        "The first route is:\n",
        "\n",
        "```python\n",
        "@app.route('/', methods=['GET'])\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "```"
      ],
      "metadata": {
        "id": "mfcp4iFASrCP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When a user tries to load the application, they initially send a request to go to the / endpoint. They will then trigger this index function above and execute the code above. Currently, the returned code from the function is a render function to show the index.html file which is the frontend interface.\n",
        "\n",
        "The second and third routes are what will be used to process all requests and handle sending information between the applications.\n",
        "\n",
        "Finally, the application is started with the app.run command to run on port 8080 and have the host be 0.0.0.0 (a.k.a. localhost)."
      ],
      "metadata": {
        "id": "qimZTeNRS3SN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Running the application ###\n",
        "\n",
        "Docker allows for the creation of “containers” that package an application and its dependencies together. This allows the application to run consistently across different environments, as the container includes everything it needs to run. Additionally, using a Docker image to create and run applications can simplify the deployment process, as the image can be easily distributed and run on any machine that has Docker installed. This can help to ensure that the application runs in the same way in development, testing, and production environments.\n",
        "\n",
        "The git clone from Step 1 already comes with a Dockerfile and requirements.txt for this application. These files are used to build the image with the dependencies already installed. Looking into the Dockerfile you can see its fairly simple, it just creates a python environment, moves all the files from the local directory to the container, installs the required packages, and then starts the application by running the python command.\n",
        "\n",
        "3 different containers need to run simultaneously to have the application run and interact with Text-to-Speech and Speech-to-Text capabilities."
      ],
      "metadata": {
        "id": "opkf_la7TCxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Small prerequisites: ###\n",
        "\n",
        "You need to run these commands with a single click to fulfill some of the prerequisites:"
      ],
      "metadata": {
        "id": "_DE7yZZrTHnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r \"/content/chatapp-with-voice-and-openai/requirements.txt\""
      ],
      "metadata": {
        "id": "4JYyXRwVV5ms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install udocker"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1bPafZFXJGk",
        "outputId": "fa8960c8-7ee9-48c8-eac3-d51ed78c426d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting udocker\n",
            "  Downloading udocker-1.3.17-py2.py3-none-any.whl.metadata (37 kB)\n",
            "Downloading udocker-1.3.17-py2.py3-none-any.whl (119 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.6/119.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: udocker\n",
            "Successfully installed udocker-1.3.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root install"
      ],
      "metadata": {
        "id": "upjsYQQ-XPp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/chatapp-with-voice-and-openai/certs/"
      ],
      "metadata": {
        "id": "pErfFE0yTK97"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root run -t voice-chatapp-image ."
      ],
      "metadata": {
        "id": "7B15MNduZ54w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!udocker --allow-root run -t voice-chatapp-image /content/chatapp-with-voice-and-openai/certs/"
      ],
      "metadata": {
        "id": "0_HBdNWAVg7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8TtE31n8WlX6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}